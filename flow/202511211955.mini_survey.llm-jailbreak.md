---
id: 202511211955.mini_survey.llm-jailbreak
title: LLM Jailbreak 手法のミニサーベイ
type: mini_survey
created_at: 2025-11-21T19:55:00+09:00
updated_at: 2025-11-21T19:55:00+09:00
status: draft
tags: [llm, jailbreak, security]
topic: LLM jailbreak 手法の有力系譜
sources:
  - https://arxiv.org/abs/2307.15043
  - https://arxiv.org/abs/2307.02483
  - https://arxiv.org/abs/2505.21556
  - https://arxiv.org/abs/2505.22037
importance: medium
timebox: "60m"
related: []
owners: []
model: gpt-5-codex
---

# 軽量サーベイ

## スコープ/基準
- テキスト/マルチモーダル LLM の安全機構を回避する攻撃系を収集（自動化・転移性・評価枠組みの有無を重視）。
- オープン実装または明確な手続きがあり、再現性が期待できるものを優先。

## 各論文サマリ
- [2307.15043] Universal and Transferable Adversarial Attacks on Aligned LMs — 勾配+貪欲探索で有害質問の語尾サフィックスを自動最適化(GCG)し、Vicuna で作ったトークン列が ChatGPT/Bard/Claude などにも高転移。
- [2307.02483] Jailbroken: How Does LLM Safety Training Fail? — 安全調整の失敗を「目標競合」「一般化不一致」に分解し、ロールプレイ/多段プロンプト設計で GPT-4/Claude v1.3 を全面突破する汎用テンプレを提示。
- [2505.21556] Benign-to-Toxic Jailbreaking — 画像だけで毒性出力を誘発する B2T 攻撃を LVLM 向けに最適化し、毒を含まないコンテキストからの安全機構崩しを実証（従来の Toxic-Continuation より強力に転移）。
- [2505.22037] Jailbreak Distillation — 既存攻撃群から有効プロンプトを自動蒸留して「枯れない」安全ベンチマークを生成し、13モデルへの汎化を確認（評価・比較基盤として有用）。

## 比較/差分
- 攻撃面: GCG はトークン級の自動最適化、Jailbroken は行動誘導テンプレ、B2T は視覚対物理の入力撹乱、Distillation は評価用プロンプト生成に特化。
- 必要条件: GCG は白箱または近似勾配が必要、Jailbroken はモデルへの長文入力だけで十分、B2T は画像最適化環境が必要、Distillation は複数モデルと攻撃器の実行コストが前提。
- 転移性: GCG/B2T はブラックボックスへ強転移を報告、Jailbroken のテンプレは対話型モデル全般に有効、Distillation は評価ベンチの更新性を重視。

## ギャップ
- 低リソース・黒箱-only 環境での自動探索（勾配不要）の強力手法が未成熟。
- LVLM 向けの防御検証が乏しく、B2T のような「非毒コンテキスト発→毒出力」検知手法が不足。
- ベンチマークが急速に陳腐化する問題に対し、オンライン運用/防御効果計測と一体化した枠組みが十分でない。

## 次アクション
- GCG 実装で自モデルの jailbreak 耐性を黒箱評価し、サフィックス長・ターゲットカテゴリごとの成功率を記録。
- Jailbroken テンプレを短文化・多言語化し、現在運用中の安全ガードに対する抜け道を洗い出す。
- B2T 系を再現できる最小画像最適化パイプラインを試作し、推論時フィルタ（CLIP/HAM10000系 NSFW 判定）との競合を測定。
- Distillation 流のベンチ生成を小規模モデル群で走らせ、社内評価セットの鮮度維持ワークフローを設計。

## References
- https://arxiv.org/abs/2307.15043
- https://arxiv.org/abs/2307.02483
- https://arxiv.org/abs/2505.21556
- https://arxiv.org/abs/2505.22037
