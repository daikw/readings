---
id: 202602091835.critique.cosmos-policy
title: Cosmos Policy クリティーク
type: critique
created_at: 2026-02-09T18:35:59+09:00
updated_at: 2026-02-09T18:35:59+09:00
status: draft
tags: [robotics, critique, policy-learning, planning, reproducibility]
topic: Cosmos Policy
sources:
  - arXiv:2601.16163
  - DOI:10.48550/arXiv.2601.16163
  - URL:https://github.com/NVlabs/cosmos-policy
  - URL:https://github.com/NVlabs/cosmos-policy/blob/main/README.md
  - URL:https://github.com/NVlabs/cosmos-policy/blob/main/cosmos_policy/config/experiment/cosmos_policy_experiment_configs.py
importance: high
timebox: "90m"
related:
  - 202602091832.paper_note.cosmos-policy
owners: []
model: gpt-5
---

# クリティーク

## 主張の要約
- 事前学習済み video diffusion（Cosmos-Predict2）へ latent frame injection を適用し、行動・未来状態・価値を単一アーキテクチャで学習/推論する主張。
- direct policy で SOTA 級の成功率、さらに rollout 追加学習した planning model を使うと難タスクの成功率が改善する主張。

## 強み
- 構造追加なしで多モダリティ制御に拡張しており、設計が比較的シンプル。
- policy/world/value の joint 学習と補助目標が、ablation 上も一貫して効いている。
- LIBERO・RoboCasa・実ロボ（ALOHA）を跨ぐ評価で、シミュレーション偏重ではない。
- コード公開範囲が広く、推論・学習・評価スクリプトまで揃っている。

## 弱み/前提
- planning 改善の鍵となる 648 rollout データは公開されておらず、追試障壁が高い。
- ALOHA planning は高レイテンシで、動的タスクへの適用可能性が限定される。
- value 集約のしきい値（例: 0.05）や多数決平均は経験則寄りで、タスク依存チューニングが必要。
- 評価は seed 固定かつ特定 HW/ソフト版（H100 + PyTorch 2.7 系）依存が強く、移植時の再現性劣化リスクが高い。
- 実ロボ比較は強いが、安全性・長期運用耐性（摩耗、温度、通信断）を定量的に扱っていない。

## 失敗モード
- 分布外初期状態で world/value が外れ、best-of-N が誤行動を増幅。
- 未来状態予測の視野欠落（遮蔽・照明変化）により価値が過大評価。
- GPU/ドライバ差異で denoising 挙動が微妙に変わり、境界タスクの成功率が不安定化。
- 実ロボでは chunk 全実行の間に異常が起きても途中修正できず、失敗が連鎖。
- 行動分布が多峰なタスクで、ensemble 設定不足だと mode collapse 的に同型失敗を繰り返す。

## 検証計画
- 再現レベル分割:
  - L1: 公開 checkpoint の direct policy を LIBERO/RoboCasa で再現（seed=195/196/197, deterministic=True）。
  - L2: ALOHA direct policy（公開 checkpoint）で4タスク平均スコア再計測。
  - L3: 自前 rollout で planning model 再学習し、難2タスクで改善幅を評価。
- 受入基準（目安）:
  - LIBERO 平均 98.5 に対して ±1.0pt 以内。
  - RoboCasa 平均 67.1 に対して ±1.0pt 以内。
  - ALOHA 平均 93.6 に対して ±3.0pt 以内（実機ノイズを考慮）。
  - planning は direct 比で難2タスク平均 +8pt 以上（論文 +12.5pt の保守的閾値）。
- 追加検証:
  - value 集約方式（average/lcb/success_vote/majority_mean）比較。
  - V(s') と Q(s,a) の同一 rollout 量でのサンプル効率比較。
  - 1/5/10 denoising step の速度-精度トレードオフ曲線化。

## References
- arXiv:2601.16163
- DOI:10.48550/arXiv.2601.16163
- URL:https://github.com/NVlabs/cosmos-policy
- URL:https://github.com/NVlabs/cosmos-policy/blob/main/README.md
- URL:https://github.com/NVlabs/cosmos-policy/blob/main/LIBERO.md
- URL:https://github.com/NVlabs/cosmos-policy/blob/main/ROBOCASA.md
- URL:https://github.com/NVlabs/cosmos-policy/blob/main/ALOHA.md
- URL:https://github.com/NVlabs/cosmos-policy/blob/main/SETUP.md
- URL:https://github.com/NVlabs/cosmos-policy/blob/main/cosmos_policy/config/experiment/cosmos_policy_experiment_configs.py
