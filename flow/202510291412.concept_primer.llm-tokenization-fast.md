---
id: 202510291412.concept_primer.llm-tokenization-fast
title: LLMトークン化の最近動向と FAST の要点
type: concept_primer
created_at: 2025-10-29T14:12:00+09:00
updated_at: 2025-10-29T14:12:00+09:00
status: draft
tags: [LLM, tokenization, VLA, robotics, compression]
topic: LLMのトークン化動向とFAST（Action Tokenization）
sources: [
  "arXiv:2501.09747",
  "arXiv:2510.18234",
  "https://github.com/karpathy/minbpe/blob/master/lecture.md#brief-taste-of-the-complexities-of-tokenization"
]
importance: high
timebox: "40m"
related: []
owners: []
model: 
---

# Concept Summary
- LLMの“トークン化”は、表現粒度・語彙設計・圧縮効率・汎多言語性・下流速度/コストに直結する中核要素。
- 2024–2025は「バイト/サブワードの頑健化」「長文/長軌跡の圧縮」「ドメイン特化（コード/数式/行動）」の最適化が進展。
- VLAでは“行動列”の離散化設計が性能/学習安定性/推論レイテンシを左右。FASTは高周波成分まで扱える周波数空間の圧縮型アクショントークナイザ。

# Core Ideas
- 語彙と粒度:
  - Byte‑level BPE/Unigramで未知語・多言語の堅牢性を確保、語彙肥大と分割過多のバランス最適化。
  - ドメイン特化トークン（コード/関数呼び出し/数式）で表現効率を改善。
- 圧縮と長文:
  - 近年は“入力側”圧縮（要約/スケッチ/光学的マッピング）や、KVキャッシュ/過去表現の圧縮活用が併走（例: DeepSeek‑OCRは2D光学写像で視覚トークン数を大幅削減）。
- マルチモーダル/行動:
  - 視覚・音声・行動トークンの“共通埋め込み空間”や、周波数/動作プリミティブへの変換で高頻度制御を圧縮。
- 訓練と推論:
  - 語彙/分割は学習ダイナミクス（学習率/カリキュラム）やKVメモリ増大と密接。タスク特化の混合語彙や分布外耐性のための正則化が検討される。

# Typical Pitfalls
- 語彙過小: 字句分割が細かすぎて列長が増大→計算/メモリ/対話遅延の悪化。
- 語彙過大: 未知語多発やドメイン外領域で分割効率が逆効果、学習が不安定。
- 多言語/形態が豊かな言語: サブワード分割が意味単位と乖離→生成品質低下。
- 行動列の離散化: 単純ビニングで高周波/相関を失い、デクス操作の性能が頭打ち。

# Canonical Examples
- 一般LLM:
  - BPE/Unigram/SentencePiece、byte‑level堅牢化、正則化（BPE‑dropout）で汎化と表現効率を両立。
  - KarpathyのminBPE講義は実装勘所と“分割の複雑さ”の良い導入。
- マルチモーダル圧縮:
  - DeepSeek‑OCR（arXiv:2510.18234）: 高解像入力を視覚トークン最適化で圧縮、長文/長文脈処理の実用例。
- 行動トークン（VLA）:
  - FAST（arXiv:2501.09747）: 離散コサイン変換（DCT）ベースで行動列を周波数空間に圧縮、デクス/高周波制御に有効。

# References
- FAST — arXiv:2501.09747
- DeepSeek‑OCR — arXiv:2510.18234
- Karpathy minBPE lecture — https://github.com/karpathy/minbpe/blob/master/lecture.md#brief-taste-of-the-complexities-of-tokenization

