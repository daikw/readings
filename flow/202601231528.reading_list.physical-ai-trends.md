---
id: 202601231528.reading_list.physical-ai-trends
title: Physical AI 関連の読む候補一覧（トレンド起点, 2020-2025）
type: reading_list
created_at: 2026-01-23T15:28:00+09:00
updated_at: 2026-01-23T15:28:00+09:00
status: draft
tags: [physical-ai, robotics, embodied-ai, manipulation, vla, trends]
topic: Physical AI
sources:
  - arXiv:2010.14406
  - arXiv:2109.12098
  - arXiv:2202.02005
  - arXiv:2204.01691
  - arXiv:2205.06175
  - arXiv:2206.11251
  - arXiv:2209.05451
  - arXiv:2210.03094
  - arXiv:2212.06817
  - arXiv:2303.03378
  - arXiv:2303.04137
  - arXiv:2304.13705
  - arXiv:2306.11706
  - arXiv:2306.14896
  - arXiv:2307.15818
  - arXiv:2309.01918
  - arXiv:2310.08864
  - arXiv:2401.02117
  - arXiv:2405.12213
  - arXiv:2406.08545
importance: high
timebox: "60m"
related: []
owners: []
model: gpt-5
---

# 読む候補一覧

## 目的/範囲
- Physical AI（Embodied AI/ロボット基盤モデル/操作学習）に関する2020-2025年の主要論文を、トレンド指標を補助にして優先度順に整理する。
- 査読付きの主要会議/ジャーナルを優先し、重要度の高いarXivプレプリントを補足的に含める。

## 選定基準
- 対象年: 2020-2025、Physical AIに直接関わる操作・行動生成・視覚言語行動（VLA）・データ/ベンチマーク。
- 除外: blog/industry report/非査読の紹介記事は一次情報として使わず、論文本体のみを採用。
- トレンド参照: arXiv Trends はキーワード出現傾向の確認用途だがサイトがJS中心のため定量抽出は限定的、alphaXiv Explore/Hot は人気シグナルとして弱参照に留める。citeturn0search2turn0search0
- 読解方針: arXiv HTML版を主に参照し、図表補足はPDFで確認する。

## 候補一覧
- Gato: A Generalist Agent — 多タスク・多モダリティの汎用エージェントとしてPhysical AIの基盤的視点を提供（安定ID: arXiv:2205.06175）。citeturn5search7
- RT-1: Robotics Transformer — 大規模実機データでロボット操作をスケールさせた基盤的アプローチ（安定ID: arXiv:2212.06817）。citeturn1search2
- RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotics — VLAによりWeb知識をロボットへ転移する代表例（安定ID: arXiv:2307.15818）。citeturn7search4
- Open X-Embodiment / RT-X — ロボット間データ統合と汎化を支える大規模データセット/学習枠組み（安定ID: arXiv:2310.08864）。citeturn1search0
- Octo: An Open-Source Generalist Robot Policy — オープンな汎用ポリシーとして再現・拡張性が高い（安定ID: arXiv:2405.12213）。citeturn1search3
- RoboCat: A self-improving generalist agent for robotic manipulation — 自己改善ループを用いた汎用操作の重要例（安定ID: arXiv:2306.11706）。citeturn2search7
- PaLM-E: An Embodied Multimodal Language Model — 大規模言語モデルと身体性の統合を示す代表作（安定ID: arXiv:2303.03378）。citeturn2search6
- Do As I Can, Not As I Say (SayCan) — 言語でタスク分解しスキル実行する枠組みの先駆（安定ID: arXiv:2204.01691）。citeturn2search3
- Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation — モバイル双腕の低コストデータ収集と学習（安定ID: arXiv:2401.02117）。citeturn3search5
- Diffusion Policy: Visuomotor Policy Learning via Action Diffusion — 拡散モデルによる視覚運動ポリシーの代表例（安定ID: arXiv:2303.04137）。citeturn2search2
- Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware (ACT) — Action Chunkingにより長期操作を扱う枠組み（安定ID: arXiv:2304.13705）。citeturn3search1
- RoboAgent: Generalization and Efficiency in Robot Manipulation via Semantic Augmentations and Action Chunking — セマンティクス拡張とアクション分割で汎化性を高める（安定ID: arXiv:2309.01918）。citeturn7search1
- RVT-2: Learning Precise Manipulation from Few Demonstrations — 少数デモからの高精度操作の最新系（安定ID: arXiv:2406.08545）。citeturn5search1
- RVT: Learning Precise Manipulation from Few Demonstrations — 少数デモ学習のベースラインとして有用（安定ID: arXiv:2306.14896）。citeturn6search7
- PerAct: Perceiver Actor for 3D Manipulation — 3D空間に強い操作ポリシーの代表例（安定ID: arXiv:2209.05451）。citeturn4search4
- VIMA: General Robot Manipulation with Multimodal Prompts — マルチモーダル・プロンプトで汎用操作を指向（安定ID: arXiv:2210.03094）。citeturn3search0
- CLIPort: What and Where Pathways for Robotic Manipulation — 言語・視覚条件付き操作の基盤（安定ID: arXiv:2109.12098）。citeturn4search0
- BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning — ゼロショット汎化の重要な参照点（安定ID: arXiv:2202.02005）。citeturn6search1
- Behavior Transformer: A Unified Approach to Behavior Learning — シーケンスモデルによる行動学習の基礎（安定ID: arXiv:2206.11251）。citeturn7search0
- Transporter Networks: Rearranging the Visual World for Robotic Manipulation — 視覚操作の古典的強力ベースライン（安定ID: arXiv:2010.14406）。citeturn6search0

## 次アクション
- 上位5本（RT-2/RT-1/RT-X/Octo/RoboCat）を先読みし、共通するデータ/スキル表現を整理する。
- VLA系（PaLM-E/SayCan/VIMA）と拡散/Transformer系（Diffusion Policy/ACT/Behavior Transformer）の差分を比較する。
- 2024-2025の実機データ収集手法（Mobile ALOHA/RVT-2）を深掘りして再現性を評価する。

## References
- arXiv:2010.14406
- arXiv:2109.12098
- arXiv:2202.02005
- arXiv:2204.01691
- arXiv:2205.06175
- arXiv:2206.11251
- arXiv:2209.05451
- arXiv:2210.03094
- arXiv:2212.06817
- arXiv:2303.03378
- arXiv:2303.04137
- arXiv:2304.13705
- arXiv:2306.11706
- arXiv:2306.14896
- arXiv:2307.15818
- arXiv:2309.01918
- arXiv:2310.08864
- arXiv:2401.02117
- arXiv:2405.12213
- arXiv:2406.08545
